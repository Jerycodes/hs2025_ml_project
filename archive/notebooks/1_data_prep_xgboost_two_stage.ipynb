{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zwei-Stufen-XGBoost – Experimentsteuerung\n",
    "\n",
    "In diesem Notebook möchte ich Experimente so aufsetzen, dass **alle Daten und Ergebnisse automatisch\n",
    "mit einer Experiment-ID versioniert werden**.\n",
    "\n",
    "Grundidee:\n",
    "\n",
    "- Ich definiere am Anfang eine `EXP_ID` (z.\\u00a0B. `v1_h4_thr0p5pct_strict`).\n",
    "- Daraus werden automatisch erzeugt:\n",
    "  - `data/processed/fx/eurusd_labels__<EXP_ID>.csv`\n",
    "  - `data/processed/datasets/eurusd_news_training__<EXP_ID>.csv`\n",
    "  - sowie jeweils die aktuelle Version ohne Suffix (`..._latest`).\n",
    "- Sp\\u00e4tere Modell-Notebooks k\\u00f6nnen diese Dateien direkt verwenden und Ergebnisse als\n",
    "  `notebooks/results/two_stage__<EXP_ID>.json` speichern.\n",
    "\n",
    "Damit ist jederzeit klar dokumentiert, **mit welchen Label-Parametern und Features ein Experiment\n",
    "durchgef\\u00fchrt wurde**, und ich kann sp\\u00e4ter leicht vergleichen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelles Arbeitsverzeichnis: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n",
      "Erkannte Projektwurzel: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Aktuelles Arbeitsverzeichnis des Kernels ermitteln.\n",
    "cwd = Path.cwd()\n",
    "print(\"Aktuelles Arbeitsverzeichnis:\", cwd)\n",
    "\n",
    "# Projektwurzel automatisch finden, indem wir nach oben laufen,\n",
    "# bis ein Ordner `src` existiert.\n",
    "project_root = cwd\n",
    "while not (project_root / \"src\").is_dir():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "print(\"Erkannte Projektwurzel:\", project_root)\n",
    "\n",
    "# Projektwurzel in den PYTHONPATH aufnehmen, damit `import src....` funktioniert.\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7d4813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbeitsverzeichnis vor Änderung: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n",
      "Arbeitsverzeichnis nach Änderung: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Diese Zelle sorgt dafür, dass das aktuelle Arbeitsverzeichnis (CWD)\n",
    "# die Projektwurzel ist. Dann zeigt `data/raw/fx/EURUSDX.csv`\n",
    "# auf die richtige Datei.\n",
    "\n",
    "print(\"Arbeitsverzeichnis vor Änderung:\", Path.cwd())\n",
    "\n",
    "# Arbeitsverzeichnis explizit auf die erkannte Projektwurzel setzen.\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"Arbeitsverzeichnis nach Änderung:\", Path.cwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment-ID und Label-Parameter definieren\n",
    "\n",
    "In dieser Zelle lege ich fest:\n",
    "\n",
    "- `EXP_ID`: eine eindeutige Bezeichnung f\\u00fcr dieses Experiment.\n",
    "- `LABEL_PARAMS`: alle Parameter, die die Label-Logik bestimmen (Horizont, Schwellen, Monotonie).\n",
    "- `OVERSAMPLE_FACTOR`: sp\\u00e4ter relevant f\\u00fcr das Oversampling der `signal=1`-F\\u00e4lle im Training.\n",
    "\n",
    "Die Idee ist, dass jede Kombination dieser Parameter als eigene Version gespeichert wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c022c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment-Konfiguration\n",
    "EXP_ID = \"s3b_h4_thr0p3pct_tol0p3_30dfeat\"  # frei w\\u00e4hlbarer Name f\\u00fcr dieses Experiment\n",
    "\n",
    "LABEL_PARAMS = dict(\n",
    "    horizon_days=4,\n",
    "    up_threshold=0.003,    # +0.5 % Lookahead-Return \\u00fcber 4 Tage\n",
    "    down_threshold=-0.003, # -0.5 % Lookahead-Return \\u00fcber 4 Tage\n",
    "    strict_monotonic=False, # Pfad t..t+4 muss streng steigend/fallend sein\n",
    "    max_adverse_move_pct = 0.003\n",
    ")\n",
    "\n",
    "# Wird sp\\u00e4ter im Trainings-Notebook verwendet, um die Bewegungs-Tage zu oversamplen.\n",
    "OVERSAMPLE_FACTOR = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "751b65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment-Konfiguration gespeichert unter: data/processed/experiments/s3b_h4_thr0p3pct_tol0p3_30dfeat_config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from src.utils.io import DATA_PROCESSED\n",
    "\n",
    "# Ordner für Experiment-Metadaten\n",
    "exp_meta_dir = DATA_PROCESSED / \"experiments\"\n",
    "exp_meta_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Konfiguration dieses Experiments (Label-Teil)\n",
    "exp_config = {\n",
    "    \"exp_id\": EXP_ID,\n",
    "    \"label_params\": LABEL_PARAMS,\n",
    "    # hier kannst du bei Bedarf noch weitere Dinge ergänzen,\n",
    "    # z.B. OVERSAMPLE_FACTOR oder Hinweise\n",
    "}\n",
    "\n",
    "exp_config_path = exp_meta_dir / f\"{EXP_ID}_config.json\"\n",
    "with exp_config_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(exp_config, f, indent=2)\n",
    "\n",
    "print(\"Experiment-Konfiguration gespeichert unter:\", exp_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Labels und Trainingsdatensatz automatisch erzeugen\n",
    "\n",
    "Die folgende Zelle erledigt den kompletten Daten-Vorbereitungsschritt automatisch:\n",
    "\n",
    "1. `label_eurusd(**LABEL_PARAMS)` berechnet die Labels im Speicher.\n",
    "2. Es werden zwei Label-Dateien geschrieben:\n",
    "   - `data/processed/fx/eurusd_labels__<EXP_ID>.csv` (archivierte Version f\\u00fcr dieses Experiment)\n",
    "   - `data/processed/fx/eurusd_labels.csv` (aktuelle Standardversion)\n",
    "3. `build_training_dataframe(exp_id=EXP_ID)` erzeugt den passenden Trainingsdatensatz aus Labels + News.\n",
    "4. Es werden zwei Trainingsdateien geschrieben:\n",
    "   - `data/processed/datasets/eurusd_news_training__<EXP_ID>.csv` (archivierte Version)\n",
    "   - `data/processed/datasets/eurusd_news_training.csv` (aktuelle Standardversion)\n",
    "\n",
    "So muss ich im Terminal **nichts mehr manuell ausf\\u00fchren**; alle relevanten CSVs entstehen beim\n",
    "Start des Experiments direkt im Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Labels gespeichert als:\n",
      "   data/processed/fx/eurusd_labels__s3b_h4_thr0p3pct_tol0p3_30dfeat.csv\n",
      "   data/processed/fx/eurusd_labels.csv\n",
      "[ok] Trainingsdatensatz gespeichert als:\n",
      "   data/processed/datasets/eurusd_news_training__s3b_h4_thr0p3pct_tol0p3_30dfeat.csv\n",
      "   data/processed/datasets/eurusd_news_training.csv\n"
     ]
    }
   ],
   "source": [
    "from src.data.label_eurusd import label_eurusd\n",
    "from src.data.build_training_set import build_training_dataframe\n",
    "from src.utils.io import DATA_PROCESSED\n",
    "\n",
    "# 1) Labels im Speicher berechnen (EURUSD-Zeitreihe + Lookahead-Logik).\n",
    "labels = label_eurusd(**LABEL_PARAMS)\n",
    "\n",
    "# Verzeichnis f\\u00fcr Label-Dateien sicherstellen.\n",
    "fx_dir = DATA_PROCESSED / \"fx\"\n",
    "fx_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Archiv-Datei mit Experiment-ID, z. B.: eurusd_labels__v1_h4_thr0p5pct_strict.csv\n",
    "labels_path_exp = fx_dir / f\"eurusd_labels__{EXP_ID}.csv\"\n",
    "labels.to_csv(labels_path_exp)\n",
    "\n",
    "# \"Aktuelle\" Datei ohne Suffix (f\\u00fcr Default-Nutzung in anderen Skripten).\n",
    "labels_path_latest = fx_dir / \"eurusd_labels.csv\"\n",
    "labels.to_csv(labels_path_latest)\n",
    "\n",
    "print(\"[ok] Labels gespeichert als:\")\n",
    "print(\"  \", labels_path_exp)\n",
    "print(\"  \", labels_path_latest)\n",
    "\n",
    "# 2) Trainingsdatensatz aus Labels + News bauen.\n",
    "# build_training_dataframe verwendet durch exp_id automatisch die passende Label-Datei.\n",
    "merged = build_training_dataframe(exp_id=EXP_ID)\n",
    "\n",
    "ds_dir = DATA_PROCESSED / \"datasets\"\n",
    "ds_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Archiv-Trainingsdatensatz mit Experiment-ID, z. B.: eurusd_news_training__v1_h4_thr0p5pct_strict.csv\n",
    "train_path_exp = ds_dir / f\"eurusd_news_training__{EXP_ID}.csv\"\n",
    "merged.to_csv(train_path_exp, index=False)\n",
    "\n",
    "# \"Aktueller\" Trainingsdatensatz ohne Suffix.\n",
    "train_path_latest = ds_dir / \"eurusd_news_training.csv\"\n",
    "merged.to_csv(train_path_latest, index=False)\n",
    "\n",
    "print(\"[ok] Trainingsdatensatz gespeichert als:\")\n",
    "print(\"  \", train_path_exp)\n",
    "print(\"  \", train_path_latest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainingsdatensatz f\\u00fcr dieses Experiment laden\n",
    "\n",
    "Ab hier kann ich im gleichen Notebook oder in weiteren Modell-Notebooks mit dem Datensatz\n",
    "\n",
    "```text\n",
    "data/processed/datasets/eurusd_news_training__<EXP_ID>.csv\n",
    "```\n",
    "\n",
    "weiterarbeiten. Die folgende Zelle zeigt, wie der Datensatz eingelesen wird;\n",
    "der Rest (Train/Val/Test-Split, XGBoost-Training, Auswertung) kann dann wie bisher erfolgen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwende Datensatz: data/processed/datasets/eurusd_news_training__s3b_h4_thr0p3pct_tol0p3_30dfeat.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>signal</th>\n",
       "      <th>direction</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>intraday_range</th>\n",
       "      <th>intraday_range_pct</th>\n",
       "      <th>body</th>\n",
       "      <th>...</th>\n",
       "      <th>cal_is_month_end</th>\n",
       "      <th>hol_is_us_federal_holiday</th>\n",
       "      <th>hol_is_day_before_us_federal_holiday</th>\n",
       "      <th>hol_is_day_after_us_federal_holiday</th>\n",
       "      <th>lookahead_return</th>\n",
       "      <th>article_count</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>avg_neg</th>\n",
       "      <th>avg_neu</th>\n",
       "      <th>avg_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005129</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>up</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.0940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>up</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>1</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>up</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>2</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>up</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>4</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    label  signal  direction  month  week  quarter  \\\n",
       "0 2020-04-14  neutral       0        NaN      4    16        2   \n",
       "1 2020-05-28       up       1        1.0      5    22        2   \n",
       "2 2020-07-15       up       1        1.0      7    29        3   \n",
       "3 2020-07-22       up       1        1.0      7    30        3   \n",
       "4 2020-10-19       up       1        1.0     10    43        4   \n",
       "\n",
       "   intraday_range  intraday_range_pct      body  ...  cal_is_month_end  \\\n",
       "0        0.006822            0.006246  0.000346  ...                 0   \n",
       "1        0.007875            0.007148  0.000158  ...                 0   \n",
       "2        0.005945            0.005210 -0.000013  ...                 0   \n",
       "3        0.009239            0.008010 -0.000106  ...                 0   \n",
       "4        0.009029            0.007707 -0.000014  ...                 0   \n",
       "\n",
       "   hol_is_us_federal_holiday  hol_is_day_before_us_federal_holiday  \\\n",
       "0                          0                                     0   \n",
       "1                          0                                     0   \n",
       "2                          0                                     0   \n",
       "3                          0                                     0   \n",
       "4                          0                                     0   \n",
       "\n",
       "   hol_is_day_after_us_federal_holiday  lookahead_return  article_count  \\\n",
       "0                                    0         -0.005129              1   \n",
       "1                                    0          0.015665              1   \n",
       "2                                    0          0.004205              1   \n",
       "3                                    0          0.020396              2   \n",
       "4                                    0          0.008495              4   \n",
       "\n",
       "   avg_polarity  avg_neg  avg_neu  avg_pos  \n",
       "0        -0.949   0.0930   0.8410   0.0660  \n",
       "1         0.518   0.0870   0.8200   0.0940  \n",
       "2         0.847   0.0800   0.8180   0.1020  \n",
       "3         0.925   0.0870   0.7850   0.1280  \n",
       "4         0.944   0.0615   0.8515   0.0865  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = DATA_PROCESSED / \"datasets\" / f\"eurusd_news_training__{EXP_ID}.csv\"\n",
    "print(\"Verwende Datensatz:\", dataset_path)\n",
    "\n",
    "df = pd.read_csv(dataset_path, parse_dates=[\"date\"])\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
