{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 – Training (Final, MT5 H1)\n",
    "\n",
    "Dieses Notebook trainiert für eine gegebene `EXP_ID` das Zwei-Stufen-\n",
    "XGBoost-Modell (Signal + Richtung). Es liest den Trainingsdatensatz\n",
    "aus `data/processed/datasets/...` und nutzt den Feature-Mode aus\n",
    "Variablen (nicht aus der EXP_ID).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb97ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erkannte Projektwurzel: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n",
      "Arbeitsverzeichnis gesetzt auf: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "cwd = Path.cwd()\n",
    "project_root = cwd\n",
    "while not (project_root / 'src').is_dir():\n",
    "    if project_root.parent == project_root:\n",
    "        raise RuntimeError(\"Projektwurzel mit 'src' nicht gefunden.\")\n",
    "    project_root = project_root.parent\n",
    "\n",
    "print('Erkannte Projektwurzel:', project_root)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "os.chdir(project_root)\n",
    "print('Arbeitsverzeichnis gesetzt auf:', Path.cwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a56970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[settings] EXP_ID: flex_5\n",
      "[settings] TRADE_PROFILE: more_trades\n",
      "[settings] USE_VALIDATION: True TRAIN_FRAC_PRETEST: 0.8\n",
      "[settings] USE_FIXED_THRESHOLDS: True AUTO_FIXED_DIR_THRESHOLDS: True\n",
      "[settings] ALLOW_DIRECTION_NEUTRAL: False\n",
      "[settings] FIXED_SIGNAL_TRADE_THRESHOLD: 0.45\n",
      "[settings] FIXED_DIR_Q_SINGLE: 0.5 FIXED_DIR_Q_DOWN/UP: 0.25 0.75 MIN_DIR_GAP: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Bitte EXP_ID explizit setzen, passend zur Data-Prep.\n",
    "EXP_ID = 'flex_5'\n",
    "assert EXP_ID != 'CHANGE_ME', 'Bitte EXP_ID oben setzen.'\n",
    "\n",
    "# True = mit News-Merge, False = nur Preise\n",
    "USE_NEWS = True\n",
    "FEATURE_MODE = 'news+price' if USE_NEWS else 'price_only'\n",
    "\n",
    "# Splits / Threshold-Tuning\n",
    "TRAIN_FRAC_PRETEST = 0.8  # später für Schritt 3 auf 0.70 setzen\n",
    "# USE_VALIDATION=False: kein Val-Split (Train nutzt alles vor test_start)\n",
    "USE_VALIDATION = True\n",
    "# 'val' (default) ist sauber; 'train' ist optimistisch; 'test' = Leakage (nicht empfohlen)\n",
    "TUNE_THRESHOLDS_ON = 'val'\n",
    "\n",
    "# Thresholding-Logik (Stage 2)\n",
    "# - True: erlaubt eine neutrale Zone (prob zwischen DOWN/UP)\n",
    "# - False: wenn Signal==1, wird immer up/down entschieden (keine Neutral-Zone)\n",
    "ALLOW_DIRECTION_NEUTRAL = True\n",
    "\n",
    "# Optional: weiche Penalty, damit die Threshold-Suche nicht zu extrem \"keine Trades\" wählt.\n",
    "# TARGET_TRADE_RATE bezieht sich auf Trades pro Signal-Trade im Val-Split (0..1). Beispiel: 0.6\n",
    "# TRADE_RATE_PENALTY ist in \"CHF\"-Punkten auf derselben Skala wie die P&L-Kostenfunktion.\n",
    "TARGET_TRADE_RATE = None\n",
    "TRADE_RATE_PENALTY = 0.0\n",
    "\n",
    "# Optimierungsziel für die Schwellen (kombinierte 3-Klassen-Entscheidung auf Val)\n",
    "# - 'pnl':    maximiert vereinfachtes P&L (kann bewusst wenig/keine Trades wählen)\n",
    "# - 'macro_f1': maximiert Macro-F1 über {neutral, up, down} (erzwingt, dass up/down nicht komplett ignoriert werden)\n",
    "THRESH_OPT_OBJECTIVE = 'macro_f1'\n",
    "\n",
    "# Optimierungsziel für DIR_THRESHOLD (nur Reporting der Direction-Metriken)\n",
    "# 'macro_f1' vermeidet degeneriert 'immer up' / 'immer down'.\n",
    "DIR_THR_OPT_OBJECTIVE = 'macro_f1'\n",
    "\n",
    "# Optional: ohne Validierung/Optimierung feste Schwellen verwenden (Baseline)\n",
    "# Trade-Profil: schneller Vergleich zwischen 'mehr Trades' und 'mehr Präzision'\n",
    "TRADE_PROFILE = 'more_trades'  # 'more_trades'|'balanced'|'more_precision'\n",
    "AUTO_FIXED_DIR_THRESHOLDS = True  # setzt DIR_THR_DOWN/UP via Quantiles aus dem Tuning-Split\n",
    "FIXED_DIR_Q_SINGLE = 0.50  # wenn ALLOW_DIRECTION_NEUTRAL=False (ein einziger DIR-Threshold)\n",
    "FIXED_DIR_Q_DOWN = 0.25\n",
    "FIXED_DIR_Q_UP = 0.75\n",
    "MIN_DIR_GAP = 0.01\n",
    "\n",
    "# Tipp: wenn du wirklich überall 0.5 willst, setze ALLOW_DIRECTION_NEUTRAL=False.\n",
    "USE_FIXED_THRESHOLDS = True\n",
    "FIXED_SIGNAL_TRADE_THRESHOLD = 0.55\n",
    "FIXED_DIR_THRESHOLD = 0.5\n",
    "# Falls ALLOW_DIRECTION_NEUTRAL=True, braucht es eine Bandbreite (sonst DOWN/UP kollidieren).\n",
    "FIXED_DIR_THRESHOLD_DOWN = 0.48\n",
    "FIXED_DIR_THRESHOLD_UP = 0.52\n",
    "\n",
    "if TRADE_PROFILE == 'more_trades':\n",
    "    # viele Trades: niedriger Signal-Filter + keine Neutral-Zone (immer up/down wenn Signal==1)\n",
    "    ALLOW_DIRECTION_NEUTRAL = False\n",
    "    FIXED_SIGNAL_TRADE_THRESHOLD = 0.45\n",
    "    FIXED_DIR_Q_SINGLE = 0.50\n",
    "elif TRADE_PROFILE == 'more_precision':\n",
    "    # weniger Trades: höherer Signal-Filter + breitere Neutral-Zone\n",
    "    ALLOW_DIRECTION_NEUTRAL = True\n",
    "    FIXED_SIGNAL_TRADE_THRESHOLD = 0.65\n",
    "    FIXED_DIR_Q_DOWN = 0.30\n",
    "    FIXED_DIR_Q_UP = 0.70\n",
    "else:  # balanced\n",
    "    ALLOW_DIRECTION_NEUTRAL = True\n",
    "    FIXED_SIGNAL_TRADE_THRESHOLD = 0.55\n",
    "    FIXED_DIR_Q_DOWN = 0.35\n",
    "    FIXED_DIR_Q_UP = 0.65\n",
    "\n",
    "print('[settings] EXP_ID:', EXP_ID)\n",
    "print('[settings] TRADE_PROFILE:', TRADE_PROFILE)\n",
    "print('[settings] USE_VALIDATION:', USE_VALIDATION, 'TRAIN_FRAC_PRETEST:', TRAIN_FRAC_PRETEST)\n",
    "print('[settings] USE_FIXED_THRESHOLDS:', USE_FIXED_THRESHOLDS, 'AUTO_FIXED_DIR_THRESHOLDS:', AUTO_FIXED_DIR_THRESHOLDS)\n",
    "print('[settings] ALLOW_DIRECTION_NEUTRAL:', ALLOW_DIRECTION_NEUTRAL)\n",
    "print('[settings] FIXED_SIGNAL_TRADE_THRESHOLD:', FIXED_SIGNAL_TRADE_THRESHOLD)\n",
    "print('[settings] FIXED_DIR_Q_SINGLE:', FIXED_DIR_Q_SINGLE, 'FIXED_DIR_Q_DOWN/UP:', FIXED_DIR_Q_DOWN, FIXED_DIR_Q_UP, 'MIN_DIR_GAP:', MIN_DIR_GAP)\n",
    "\n",
    "\n",
    "# Optional: XGBoost-Parameter überschreiben (z.B. max_depth)\n",
    "# Hinweis: zu hohe max_depth führt oft zu Overfitting (Train gut, Val/Test schlechter).\n",
    "SIGNAL_XGB_PARAMS = {'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 2.0}\n",
    "DIRECTION_XGB_PARAMS = {'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 2.0}\n",
    "\n",
    "# Optional: zusätzlich ein direktes 3-Klassen-Modell (neutral/up/down) als Baseline trainieren\n",
    "TRAIN_MULTICLASS_BASELINE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "341e4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwende Datensatz: data/processed/datasets/eurusd_news_training__flex_5.csv\n",
      "(1169, 60)\n",
      "Feature-Spalten: 44\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.io import DATA_PROCESSED\n",
    "from src.models.train_xgboost_two_stage import (\n",
    "    split_train_val_test,\n",
    "    build_signal_targets,\n",
    "    build_direction_targets,\n",
    "    train_xgb_binary,\n",
    "    get_feature_cols,\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# Datensatz laden\n",
    "# Feature-Mode aus Data-Prep-Config übernehmen (verhindert Mismatch zwischen 1_data_prep und 2_train)\n",
    "exp_meta_dir = DATA_PROCESSED / 'experiments'\n",
    "exp_config_path = exp_meta_dir / f'{EXP_ID}_config.json'\n",
    "if not exp_config_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f'Experiment-Config nicht gefunden: {exp_config_path}\\n'\n",
    "        '→ Bitte zuerst notebooks/final_two_stage_h1/1_data_prep_h1.ipynb mit derselben EXP_ID ausführen.'\n",
    "    )\n",
    "with exp_config_path.open('r', encoding='utf-8') as f:\n",
    "    exp_config = json.load(f)\n",
    "cfg_feature_mode = exp_config.get('feature_mode')\n",
    "if cfg_feature_mode in {'price_only', 'news+price'}:\n",
    "    if cfg_feature_mode != FEATURE_MODE:\n",
    "        print(f\"[info] FEATURE_MODE überschrieben durch Config: {FEATURE_MODE} -> {cfg_feature_mode}\")\n",
    "    FEATURE_MODE = cfg_feature_mode\n",
    "\n",
    "ds_kind = 'news' if FEATURE_MODE=='news+price' else 'price'\n",
    "ds_filename = f\"eurusd_{ds_kind}_training__{EXP_ID}.csv\"\n",
    "ds_path = DATA_PROCESSED / 'datasets' / ds_filename\n",
    "print('Verwende Datensatz:', ds_path)\n",
    "if not ds_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Datensatz nicht gefunden: {ds_path}\\n\"\n",
    "        \"→ Bitte zuerst das Data-Prep-Notebook (notebooks/final_two_stage_h1/1_data_prep_h1.ipynb) mit genau derselben EXP_ID ausführen.\"\n",
    "    )\n",
    "df = pd.read_csv(ds_path, parse_dates=['date']).sort_values('date').reset_index(drop=True)\n",
    "print(df.shape)\n",
    "base_cols = get_feature_cols(df)\n",
    "if FEATURE_MODE == 'price_only':\n",
    "    news_cols = {\n",
    "        'article_count','avg_polarity','avg_neg','avg_neu','avg_pos','pos_share','neg_share'\n",
    "    }\n",
    "    feature_cols = [c for c in base_cols if not c.startswith('news_') and c not in news_cols]\n",
    "else:\n",
    "    feature_cols = base_cols\n",
    "\n",
    "print('Feature-Spalten:', len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1767994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2020-04-14 -> 2024-04-09 n= 755\n",
      "val 2024-04-10 -> 2024-12-31 n= 189\n",
      "test 2025-01-02 -> 2025-11-12 n= 225\n"
     ]
    }
   ],
   "source": [
    "# Zeitliche Splits\n",
    "test_start = '2025-01-01'\n",
    "train_frac_pretest = float(TRAIN_FRAC_PRETEST) if USE_VALIDATION else 1.0\n",
    "\n",
    "splits = split_train_val_test(\n",
    "    df, pd.to_datetime(test_start), train_frac_within_pretest=train_frac_pretest\n",
    ")\n",
    "for name, split_df in splits.items():\n",
    "    print(name, split_df['date'].min().date(), '->', split_df['date'].max().date(), 'n=', len(split_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44f2803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_dir (186, 44)\n",
      "y_train_dir unique: (array([0, 1]), array([108,  78]))\n",
      "train signal counts: {0: 569, 1: 186}\n",
      "train direction counts (signal==1): {0.0: 108, 1.0: 78}\n"
     ]
    }
   ],
   "source": [
    "# Optional: Debug-Zelle (nur nötig, wenn du etwas prüfen willst).\n",
    "# Hinweis: Diese Zelle funktioniert erst, nachdem oben Datensatz+Splits geladen wurden.\n",
    "if 'splits' not in globals() or 'feature_cols' not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"Bitte zuerst die Zellen oben ausführen (Datensatz laden + Splits + feature_cols).\"\n",
    "    )\n",
    "if 'X_train_dir' not in globals() or 'y_train_dir' not in globals():\n",
    "    X_train_dir, y_train_dir = build_direction_targets(splits['train'], feature_cols=feature_cols)\n",
    "\n",
    "print('X_train_dir', getattr(X_train_dir, 'shape', None))\n",
    "print('y_train_dir unique:', np.unique(y_train_dir, return_counts=True))\n",
    "print('train signal counts:', splits['train']['signal'].value_counts().to_dict())\n",
    "print('train direction counts (signal==1):', splits['train'].query('signal==1')['direction'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d06f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal scale_pos_weight: 3.0591397849462365\n",
      "[ok] Signal-Modell trainiert.\n",
      "[debug] Signal boosted rounds: 109\n",
      "[debug] Signal best_iteration: 58\n",
      "[debug] Signal best_score: 0.6430864583247553\n",
      "[debug] Signal scale_pos_weight (used): 3.0591397849462365\n",
      "[debug] Signal train counts: {0: 569, 1: 186}\n",
      "[debug] Signal val counts  : {0: 151, 1: 38}\n",
      "[debug] Signal test counts : {0: 166, 1: 59}\n",
      "[debug] Direction train X/y: (186, 44) {0: 108, 1: 78}\n",
      "[debug] Direction val   X/y: (38, 44) {0: 23, 1: 15}\n",
      "[debug] Direction test  X/y: (59, 44) {0: 19, 1: 40}\n",
      "Direction scale_pos_weight: 1.3846153846153846\n",
      "[ok] Richtungs-Modell trainiert.\n",
      "[debug] Direction boosted rounds: 51\n",
      "[debug] Direction best_iteration: 0\n",
      "[debug] Direction best_score: 0.7020537492476011\n",
      "[debug] Direction scale_pos_weight (used): 1.3846153846153846\n",
      "Richtungs-Schwelle (val-basiert): 0.5 macro_f1(val): 0.3909407665505227\n",
      "[fixed] TRADE_PROFILE: more_trades\n",
      "[fixed] SIG_THR_TRADE: 0.45 DIR_THR_DOWN/UP: 0.5065287351608276 0.5065287351608276 split: val\n",
      "[fixed][counts] train {'n': 755, 'signal_trade': 434, 'up': 147, 'down': 287, 'neutral': 321}\n",
      "[fixed][counts] val {'n': 189, 'signal_trade': 103, 'up': 58, 'down': 45, 'neutral': 86}\n",
      "[fixed][counts] test {'n': 225, 'signal_trade': 103, 'up': 48, 'down': 55, 'neutral': 122}\n",
      "[mc] class counts train: {0: 569, 1: 78, 2: 108} weights: {0: 0.44229642647920325, 1: 3.2264957264957266, 2: 2.330246913580247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] 3-Klassen-Baseline trainiert.\n",
      "[ok] Ergebnisse gespeichert unter:\n",
      "   JSON base : notebooks/results/two_stage__flex_5.json\n",
      "   JSON final: notebooks/results/final_two_stage/two_stage_final__flex_5.json\n",
      "   CSV final : notebooks/results/final_two_stage/two_stage_final__flex_5_metrics.csv\n",
      "   Predictions: notebooks/results/final_two_stage/two_stage_final__flex_5_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "\n",
    "# Schwelle für das Signal-Modell (Stufe 1).\n",
    "# Höhere Werte -> höhere Precision, geringerer Recall.\n",
    "SIGNAL_THRESHOLD = 0.5\n",
    "\n",
    "# --- Signal-Modell trainieren ---\n",
    "y_train_signal = build_signal_targets(splits['train'])\n",
    "y_val_signal   = build_signal_targets(splits['val'])\n",
    "y_test_signal  = build_signal_targets(splits['test'])\n",
    "\n",
    "X_train_signal = splits['train'][feature_cols]\n",
    "X_val_signal   = splits['val'][feature_cols]\n",
    "X_test_signal  = splits['test'][feature_cols]\n",
    "\n",
    "# Class-Imbalance für das Signal-Modell explizit berücksichtigen\n",
    "n_pos_signal = int((y_train_signal == 1).sum())\n",
    "n_neg_signal = int((y_train_signal == 0).sum())\n",
    "scale_pos_weight_signal = n_neg_signal / max(n_pos_signal, 1)\n",
    "print('Signal scale_pos_weight:', scale_pos_weight_signal)\n",
    "\n",
    "model_signal = train_xgb_binary(\n",
    "    X_train_signal,\n",
    "    y_train_signal,\n",
    "    X_val_signal,\n",
    "    y_val_signal,\n",
    "    scale_pos_weight=scale_pos_weight_signal,\n",
    "    xgb_params=SIGNAL_XGB_PARAMS,\n",
    ")\n",
    "print('[ok] Signal-Modell trainiert.')\n",
    "try:\n",
    "    _b = model_signal.get_booster()\n",
    "    print('[debug] Signal boosted rounds:', _b.num_boosted_rounds())\n",
    "    if hasattr(model_signal, 'best_iteration'):\n",
    "        print('[debug] Signal best_iteration:', getattr(model_signal, 'best_iteration', None))\n",
    "    if hasattr(model_signal, 'best_score'):\n",
    "        print('[debug] Signal best_score:', getattr(model_signal, 'best_score', None))\n",
    "    print('[debug] Signal scale_pos_weight (used):', model_signal.get_xgb_params().get('scale_pos_weight'))\n",
    "except Exception as e:\n",
    "    print('[warn] Konnte Signal-Booster-Infos nicht lesen:', e)\n",
    "\n",
    "# --- Richtungs-Modell trainieren ---\n",
    "X_train_dir, y_train_dir = build_direction_targets(splits['train'], feature_cols=feature_cols)\n",
    "X_val_dir,   y_val_dir   = build_direction_targets(splits['val'],   feature_cols=feature_cols)\n",
    "X_test_dir,  y_test_dir  = build_direction_targets(splits['test'],  feature_cols=feature_cols)\n",
    "\n",
    "def _count01(y):\n",
    "    if y is None or len(y) == 0:\n",
    "        return {}\n",
    "    u, c = np.unique(y, return_counts=True)\n",
    "    return {int(uu): int(cc) for uu, cc in zip(u, c)}\n",
    "\n",
    "print('[debug] Signal train counts:', _count01(y_train_signal))\n",
    "print('[debug] Signal val counts  :', _count01(y_val_signal))\n",
    "print('[debug] Signal test counts :', _count01(y_test_signal))\n",
    "print('[debug] Direction train X/y:', getattr(X_train_dir, 'shape', None), _count01(y_train_dir))\n",
    "print('[debug] Direction val   X/y:', getattr(X_val_dir, 'shape', None), _count01(y_val_dir))\n",
    "print('[debug] Direction test  X/y:', getattr(X_test_dir, 'shape', None), _count01(y_test_dir))\n",
    "if len(X_val_dir) == 0:\n",
    "    print(\"[warn] Val-Split hat 0 Bewegungstage (signal==1) → DIR_THRESHOLD kann nicht val-basiert optimiert werden.\")\n",
    "if len(X_test_dir) == 0:\n",
    "    print(\"[warn] Test-Split hat 0 Bewegungstage (signal==1) → Direction-Metriken sind leer.\")\n",
    "\n",
    "# Class-Imbalance für das Richtungs-Modell berücksichtigen\n",
    "# (positive Klasse = up=1, negative Klasse = down=0)\n",
    "n_pos_dir = int((y_train_dir == 1).sum())\n",
    "n_neg_dir = int((y_train_dir == 0).sum())\n",
    "scale_pos_weight_dir = n_neg_dir / max(n_pos_dir, 1)\n",
    "print('Direction scale_pos_weight:', scale_pos_weight_dir)\n",
    "\n",
    "model_dir = train_xgb_binary(\n",
    "    X_train_dir,\n",
    "    y_train_dir,\n",
    "    X_val_dir,\n",
    "    y_val_dir,\n",
    "    scale_pos_weight=scale_pos_weight_dir,\n",
    "    xgb_params=DIRECTION_XGB_PARAMS,\n",
    ")\n",
    "print('[ok] Richtungs-Modell trainiert.')\n",
    "try:\n",
    "    _b = model_dir.get_booster()\n",
    "    print('[debug] Direction boosted rounds:', _b.num_boosted_rounds())\n",
    "    if hasattr(model_dir, 'best_iteration'):\n",
    "        print('[debug] Direction best_iteration:', getattr(model_dir, 'best_iteration', None))\n",
    "    if hasattr(model_dir, 'best_score'):\n",
    "        print('[debug] Direction best_score:', getattr(model_dir, 'best_score', None))\n",
    "    print('[debug] Direction scale_pos_weight (used):', model_dir.get_xgb_params().get('scale_pos_weight'))\n",
    "except Exception as e:\n",
    "    print('[warn] Konnte Direction-Booster-Infos nicht lesen:', e)\n",
    "\n",
    "# --- Metriken berechnen und speichern ---\n",
    "\n",
    "def binary_metrics_dict(y_true, y_prob, threshold, target_names):\n",
    "    if y_true is None or len(y_true) == 0:\n",
    "        return {\n",
    "            'threshold': float(threshold),\n",
    "            'report': {},\n",
    "            'confusion_matrix': [],\n",
    "        }\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=target_names,\n",
    "        output_dict=True,\n",
    "        digits=3,\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return {\n",
    "        'threshold': float(threshold),\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm,\n",
    "    }\n",
    "\n",
    "def proba_pos(model, X):\n",
    "    \"\"\"P(positive Klasse) als 1D-Array; liefert [] wenn X leer ist.\"\"\"\n",
    "    if X is None or len(X) == 0:\n",
    "        return np.array([])\n",
    "    proba = model.predict_proba(X)\n",
    "    if getattr(proba, 'ndim', 0) != 2 or proba.shape[1] < 2:\n",
    "        raise ValueError(\n",
    "            f\"predict_proba lieferte unerwartete Form {getattr(proba, 'shape', None)}. \"\n",
    "            \"Das Modell ist evtl. degeneriert (z.B. Training hatte nur 1 Klasse oder leere Daten).\"\n",
    "        )\n",
    "    return proba[:, 1]\n",
    "\n",
    "# Wahrscheinlichkeiten\n",
    "p_train_signal = proba_pos(model_signal, X_train_signal)\n",
    "p_val_signal   = proba_pos(model_signal, X_val_signal)\n",
    "p_test_signal  = proba_pos(model_signal, X_test_signal)\n",
    "\n",
    "signal_metrics = {\n",
    "    'train': binary_metrics_dict(y_train_signal, p_train_signal, SIGNAL_THRESHOLD, ['neutral', 'move']),\n",
    "    'val':   binary_metrics_dict(y_val_signal,   p_val_signal,   SIGNAL_THRESHOLD, ['neutral', 'move']),\n",
    "    'test':  binary_metrics_dict(y_test_signal,  p_test_signal,  SIGNAL_THRESHOLD, ['neutral', 'move']),\n",
    "}\n",
    "\n",
    "p_train_dir = proba_pos(model_dir, X_train_dir)\n",
    "p_val_dir   = proba_pos(model_dir, X_val_dir)\n",
    "p_test_dir  = proba_pos(model_dir, X_test_dir)\n",
    "\n",
    "# Threshold für das Richtungs-Modell (down vs up) anhand des Val-Splits optimieren\n",
    "# Hinweis: DIR_THRESHOLD beeinflusst nur die *Reporting*-Metriken für das Direction-Modell.\n",
    "# Für die kombinierte 3-Klassen-Entscheidung werden SIG_THR_TRADE + DIR_THR_DOWN/UP verwendet.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "DIR_THRESHOLD = 0.5\n",
    "best_score_dir = None\n",
    "if y_val_dir is not None and len(y_val_dir) > 0 and len(np.unique(y_val_dir)) > 1:\n",
    "    thr_grid = np.linspace(0.2, 0.8, 31)\n",
    "    best_thr = 0.5\n",
    "    best_score_dir = -1.0\n",
    "    for thr in thr_grid:\n",
    "        y_val_pred = (p_val_dir >= thr).astype(int)\n",
    "        if DIR_THR_OPT_OBJECTIVE == 'f1_up':\n",
    "            rep = classification_report(\n",
    "                y_val_dir,\n",
    "                y_val_pred,\n",
    "                target_names=['down', 'up'],\n",
    "                output_dict=True,\n",
    "                digits=3,\n",
    "                zero_division=0,\n",
    "            )\n",
    "            score = float(rep.get('up', {}).get('f1-score', -1.0))\n",
    "        else:\n",
    "            # macro_f1 (default) -> verhindert degenerierte Lösungen\n",
    "            score = float(f1_score(y_val_dir, y_val_pred, average='macro', zero_division=0))\n",
    "\n",
    "        if score > best_score_dir:\n",
    "            best_score_dir = score\n",
    "            best_thr = thr\n",
    "\n",
    "    DIR_THRESHOLD = float(best_thr)\n",
    "    print('Richtungs-Schwelle (val-basiert):', DIR_THRESHOLD, f\"{DIR_THR_OPT_OBJECTIVE}(val):\", best_score_dir)\n",
    "else:\n",
    "    print('[warn] Val-Split hat zu wenig Direction-Samples (0 oder nur 1 Klasse) → DIR_THRESHOLD=0.5')\n",
    "\n",
    "direction_metrics = {\n",
    "    'train': binary_metrics_dict(y_train_dir, p_train_dir, DIR_THRESHOLD, ['down', 'up']),\n",
    "    'val':   binary_metrics_dict(y_val_dir,   p_val_dir,   DIR_THRESHOLD, ['down', 'up']),\n",
    "    'test':  binary_metrics_dict(y_test_dir,  p_test_dir,  DIR_THRESHOLD, ['down', 'up']),\n",
    "}\n",
    "\n",
    "# --- Kostenbasierte Schwellen für das Richtungs-Modell bestimmen ---\n",
    "from src.utils.io import DATA_PROCESSED  # für Zugriff auf Experiment-Config\n",
    "exp_meta_dir = DATA_PROCESSED / 'experiments'\n",
    "exp_config_path = exp_meta_dir / f'{EXP_ID}_config.json'\n",
    "with exp_config_path.open('r', encoding='utf-8') as f:\n",
    "    _cfg = json.load(f)\n",
    "label_params = _cfg.get('label_params', {})\n",
    "up_thr_label = float(label_params.get('up_threshold', 0.0))\n",
    "down_thr_label = float(label_params.get('down_threshold', 0.0))\n",
    "max_adv_label = label_params.get('max_adverse_move_pct', 0.01) or 0.01\n",
    "\n",
    "# Einsatz-Größen für die Kostenfunktion (müssen zu Strategie A im Report passen)\n",
    "stake_up = 100.0\n",
    "stake_down = 100.0\n",
    "\n",
    "def cost_per_trade(true_label: str, pred_label: str) -> float:\n",
    "    \"\"\"Approx. Trade-Kosten in CHF für Strategie A.\n",
    "\n",
    "    Vereinfachte Annahme:\n",
    "    - Korrekte Trades verdienen ca. Schwelle * Einsatz.\n",
    "    - Falsche Trades bzw. Trades auf neutralen Tagen verlieren ca.\n",
    "      max_adverse_move_pct * Einsatz.\n",
    "    \"\"\"\n",
    "    true_label = str(true_label)\n",
    "    pred_label = str(pred_label)\n",
    "\n",
    "    if pred_label == 'neutral':\n",
    "        return 0.0\n",
    "    if true_label == 'neutral':\n",
    "        # konservativ: immer Stop-Loss\n",
    "        return -stake_up * max_adv_label if pred_label == 'up' else -stake_down * max_adv_label\n",
    "    if pred_label == 'up':\n",
    "        if true_label == 'up':\n",
    "            return stake_up * up_thr_label\n",
    "        else:  # true_label == 'down'\n",
    "            return -stake_up * max_adv_label\n",
    "    if pred_label == 'down':\n",
    "        if true_label == 'down':\n",
    "            return stake_down * (-down_thr_label)\n",
    "        else:  # true_label == 'up'\n",
    "            return -stake_down * max_adv_label\n",
    "    return 0.0\n",
    "\n",
    "# --- Schwellen (Signal + Richtung) ---\n",
    "TUNE_SPLIT = None\n",
    "# Wenn USE_FIXED_THRESHOLDS=True: nutze fixe Werte (Baseline, kein Tuning).\n",
    "# Sonst: gemeinsame Optimierung auf dem gewählten Tuning-Split.\n",
    "if USE_FIXED_THRESHOLDS:\n",
    "    SIG_THR_TRADE = float(FIXED_SIGNAL_TRADE_THRESHOLD)\n",
    "    # Für Auto-Quantile brauchen wir einen Split mit Daten.\n",
    "    split_for_fixed = 'val' if (USE_VALIDATION and len(splits.get('val', [])) > 0) else 'train'\n",
    "    TUNE_SPLIT = f'fixed:{split_for_fixed}'\n",
    "\n",
    "    if ALLOW_DIRECTION_NEUTRAL:\n",
    "        # Entweder feste Bandbreite oder automatisch via Quantile der Direction-Probabilities\n",
    "        if AUTO_FIXED_DIR_THRESHOLDS:\n",
    "            p_sig_map = {'train': p_train_signal, 'val': p_val_signal, 'test': p_test_signal}\n",
    "            p_sig = p_sig_map[split_for_fixed]\n",
    "            p_dir = proba_pos(model_dir, splits[split_for_fixed][feature_cols])\n",
    "            sig_trade = (p_sig >= SIG_THR_TRADE)\n",
    "            p_trade = p_dir[sig_trade] if len(p_dir) else np.array([])\n",
    "            if len(p_trade):\n",
    "                qd = float(np.quantile(p_trade, float(FIXED_DIR_Q_DOWN)))\n",
    "                qu = float(np.quantile(p_trade, float(FIXED_DIR_Q_UP)))\n",
    "                # sicherstellen, dass es eine echte Neutral-Zone gibt\n",
    "                if qu - qd < float(MIN_DIR_GAP):\n",
    "                    mid = 0.5 * (qd + qu)\n",
    "                    qd = float(max(0.0, mid - 0.5 * float(MIN_DIR_GAP)))\n",
    "                    qu = float(min(1.0, mid + 0.5 * float(MIN_DIR_GAP)))\n",
    "                DIR_THR_DOWN = qd\n",
    "                DIR_THR_UP = qu\n",
    "            else:\n",
    "                DIR_THR_DOWN = float(FIXED_DIR_THRESHOLD_DOWN)\n",
    "                DIR_THR_UP = float(FIXED_DIR_THRESHOLD_UP)\n",
    "        else:\n",
    "            DIR_THR_DOWN = float(FIXED_DIR_THRESHOLD_DOWN)\n",
    "            DIR_THR_UP = float(FIXED_DIR_THRESHOLD_UP)\n",
    "    else:\n",
    "        # Keine Neutral-Zone: ein einziger Threshold (P(up) >= thr => up, sonst down)\n",
    "        if AUTO_FIXED_DIR_THRESHOLDS:\n",
    "            p_sig_map = {'train': p_train_signal, 'val': p_val_signal, 'test': p_test_signal}\n",
    "            p_sig = p_sig_map[split_for_fixed]\n",
    "            p_dir = proba_pos(model_dir, splits[split_for_fixed][feature_cols])\n",
    "            sig_trade = (p_sig >= SIG_THR_TRADE)\n",
    "            p_trade = p_dir[sig_trade] if len(p_dir) else np.array([])\n",
    "            if len(p_trade):\n",
    "                thr = float(np.quantile(p_trade, float(FIXED_DIR_Q_SINGLE)))\n",
    "            else:\n",
    "                thr = float(FIXED_DIR_THRESHOLD)\n",
    "        else:\n",
    "            thr = float(FIXED_DIR_THRESHOLD)\n",
    "        DIR_THR_DOWN = thr\n",
    "        DIR_THR_UP = thr\n",
    "\n",
    "    print('[fixed] TRADE_PROFILE:', TRADE_PROFILE)\n",
    "    print('[fixed] SIG_THR_TRADE:', SIG_THR_TRADE, 'DIR_THR_DOWN/UP:', DIR_THR_DOWN, DIR_THR_UP, 'split:', split_for_fixed)\n",
    "\n",
    "    def _combined_counts(p_sig: np.ndarray, p_dir: np.ndarray) -> dict:\n",
    "        if p_sig is None or len(p_sig) == 0:\n",
    "            return {'n': 0, 'signal_trade': 0, 'up': 0, 'down': 0, 'neutral': 0}\n",
    "        mask = (p_sig >= SIG_THR_TRADE)\n",
    "        n_signal = int(mask.sum())\n",
    "        if p_dir is None or len(p_dir) == 0:\n",
    "            return {'n': int(len(p_sig)), 'signal_trade': n_signal, 'up': 0, 'down': 0, 'neutral': int(len(p_sig) - n_signal)}\n",
    "\n",
    "        if not ALLOW_DIRECTION_NEUTRAL:\n",
    "            # Partition ohne Neutral-Zone: >= thr => up, < thr => down (keine Überlappung)\n",
    "            up = int(np.sum(mask & (p_dir >= DIR_THR_UP)))\n",
    "            down = int(n_signal - up)\n",
    "            neutral = int(len(p_sig) - n_signal)\n",
    "        else:\n",
    "            up = int(np.sum(mask & (p_dir >= DIR_THR_UP)))\n",
    "            down = int(np.sum(mask & (p_dir <= DIR_THR_DOWN)))\n",
    "            neutral = int(len(p_sig) - up - down)\n",
    "        return {'n': int(len(p_sig)), 'signal_trade': n_signal, 'up': up, 'down': down, 'neutral': neutral}\n",
    "\n",
    "    for _split, _p_sig, _df_split in [\n",
    "        ('train', p_train_signal, splits['train']),\n",
    "        ('val', p_val_signal, splits['val']),\n",
    "        ('test', p_test_signal, splits['test']),\n",
    "    ]:\n",
    "        _p_dir = proba_pos(model_dir, _df_split[feature_cols])\n",
    "        print('[fixed][counts]', _split, _combined_counts(_p_sig, _p_dir))\n",
    "else:\n",
    "    # --- Schwellen (Signal + Richtung) gemeinsam optimieren ---\n",
    "    # Wichtig: getrennte Optimierung kann inkonsistent werden (z.B. Direction-Thresholds\n",
    "    # werden für SIGNAL_THRESHOLD=0.5 optimiert, Trade-Threshold aber später geändert).\n",
    "    #\n",
    "    # Tuning-Split:\n",
    "    # - 'val'  (default): sauber, kein Leakage\n",
    "    # - 'train': erlaubt, aber optimistisch (Thresholds werden auf Trainingsdaten optimiert)\n",
    "    # - 'test' : NICHT empfohlen → Leakage, Ergebnis nicht mehr vergleichbar\n",
    "    TUNE_SPLIT = str(TUNE_THRESHOLDS_ON)\n",
    "    if TUNE_SPLIT not in {'train', 'val', 'test'}:\n",
    "        raise ValueError(\"TUNE_THRESHOLDS_ON muss 'train', 'val' oder 'test' sein.\")\n",
    "    if TUNE_SPLIT == 'test':\n",
    "        print('[warn] TUNE_THRESHOLDS_ON=\"test\" → Daten-Leakage. Test-Metriken sind dann optimistisch und nicht mehr fair.')\n",
    "    if len(splits.get(TUNE_SPLIT, [])) == 0:\n",
    "        print(f\"[warn] Split '{TUNE_SPLIT}' ist leer → fallback auf 'train' für Threshold-Tuning.\")\n",
    "        TUNE_SPLIT = 'train'\n",
    "\n",
    "    labels_tune = splits[TUNE_SPLIT]['label'].to_numpy()\n",
    "\n",
    "    p_signal_map = {'train': p_train_signal, 'val': p_val_signal, 'test': p_test_signal}\n",
    "    p_tune_signal = p_signal_map[TUNE_SPLIT]\n",
    "\n",
    "    signal_pred_tune = (p_tune_signal >= SIGNAL_THRESHOLD).astype(int)\n",
    "    p_tune_dir_all = proba_pos(model_dir, splits[TUNE_SPLIT][feature_cols])\n",
    "\n",
    "    # Kandidaten dynamisch an die tatsächlich vorhergesagten Wahrscheinlichkeiten anpassen,\n",
    "    # sonst kann die Optimierung eine Schwelle wählen, die nie erreicht wird (-> alles neutral).\n",
    "    p_tune_trade = p_tune_dir_all[signal_pred_tune == 1] if len(p_tune_dir_all) else np.array([])\n",
    "    if len(p_tune_trade):\n",
    "        lo = float(np.nanmin(p_tune_trade))\n",
    "        hi = float(np.nanmax(p_tune_trade))\n",
    "        if not np.isfinite(lo) or not np.isfinite(hi) or lo == hi:\n",
    "            thr_candidates = np.linspace(0.3, 0.7, 17)\n",
    "        else:\n",
    "            # etwas Puffer, damit die Grenzen auch erreichbar sind\n",
    "            pad = 0.01\n",
    "            thr_candidates = np.linspace(max(0.0, lo - pad), min(1.0, hi + pad), 17)\n",
    "    else:\n",
    "        thr_candidates = np.linspace(0.3, 0.7, 17)\n",
    "\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    thr_sig_candidates = np.linspace(0.3, 0.7, 17)\n",
    "    best_score = -1e18\n",
    "    best_pnl = -1e18\n",
    "    best_macro_f1 = -1.0\n",
    "    best_sig_thr = SIGNAL_THRESHOLD\n",
    "    best_thr_down = float(np.nanmin(thr_candidates)) if len(thr_candidates) else 0.4\n",
    "    best_thr_up = float(np.nanmax(thr_candidates)) if len(thr_candidates) else 0.6\n",
    "    best_thr_single = 0.5\n",
    "    best_trade_rate = None\n",
    "    best_counts = None\n",
    "\n",
    "    def _apply_trade_rate_penalty(pnl: float, trade_rate: float | None) -> float:\n",
    "        if TARGET_TRADE_RATE is None or TRADE_RATE_PENALTY <= 0 or trade_rate is None:\n",
    "            return float(pnl)\n",
    "        return float(pnl) - float(TRADE_RATE_PENALTY) * abs(float(trade_rate) - float(TARGET_TRADE_RATE))\n",
    "\n",
    "    for thr_sig in thr_sig_candidates:\n",
    "        sig_trade = (p_tune_signal >= thr_sig)\n",
    "        n_signal = int(sig_trade.sum())\n",
    "\n",
    "        if not ALLOW_DIRECTION_NEUTRAL:\n",
    "            # Keine Neutral-Zone: wenn Signal==1, immer up/down.\n",
    "            for thr in thr_candidates:\n",
    "                pred = np.full(len(labels_tune), 'neutral', dtype=object)\n",
    "                pred[sig_trade & (p_tune_dir_all >= thr)] = 'up'\n",
    "                pred[sig_trade & (p_tune_dir_all < thr)] = 'down'\n",
    "\n",
    "                n_trades = n_signal\n",
    "                n_up = int((pred == 'up').sum())\n",
    "                n_down = int((pred == 'down').sum())\n",
    "                trade_rate = (n_trades / max(n_signal, 1)) if n_signal > 0 else None\n",
    "\n",
    "                pnl = float(sum(cost_per_trade(t, p) for t, p in zip(labels_tune, pred)))\n",
    "                macro_f1 = float(f1_score(labels_tune, pred, labels=['neutral', 'up', 'down'], average='macro', zero_division=0))\n",
    "\n",
    "                if THRESH_OPT_OBJECTIVE == 'macro_f1':\n",
    "                    score = macro_f1\n",
    "                else:\n",
    "                    score = _apply_trade_rate_penalty(pnl, trade_rate)\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_pnl = pnl\n",
    "                    best_macro_f1 = macro_f1\n",
    "                    best_sig_thr = float(thr_sig)\n",
    "                    best_thr_single = float(thr)\n",
    "                    best_thr_down = float(thr)\n",
    "                    best_thr_up = float(thr)\n",
    "                    best_trade_rate = trade_rate\n",
    "                    best_counts = {'signal': n_signal, 'trades': n_trades, 'up': n_up, 'down': n_down}\n",
    "        else:\n",
    "            # Neutral-Zone: up nur wenn prob>=UP, down nur wenn prob<=DOWN.\n",
    "            for thr_down in thr_candidates:\n",
    "                for thr_up in thr_candidates:\n",
    "                    if thr_down >= thr_up:\n",
    "                        continue\n",
    "                    pred = np.full(len(labels_tune), 'neutral', dtype=object)\n",
    "                    pred[sig_trade & (p_tune_dir_all >= thr_up)] = 'up'\n",
    "                    pred[sig_trade & (p_tune_dir_all <= thr_down)] = 'down'\n",
    "\n",
    "                    n_trades = int((pred != 'neutral').sum())\n",
    "                    n_up = int((pred == 'up').sum())\n",
    "                    n_down = int((pred == 'down').sum())\n",
    "                    trade_rate = (n_trades / max(n_signal, 1)) if n_signal > 0 else None\n",
    "\n",
    "                    pnl = float(sum(cost_per_trade(t, p) for t, p in zip(labels_tune, pred)))\n",
    "                    macro_f1 = float(f1_score(labels_tune, pred, labels=['neutral', 'up', 'down'], average='macro', zero_division=0))\n",
    "\n",
    "                    if THRESH_OPT_OBJECTIVE == 'macro_f1':\n",
    "                        score = macro_f1\n",
    "                    else:\n",
    "                        score = _apply_trade_rate_penalty(pnl, trade_rate)\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_pnl = pnl\n",
    "                        best_macro_f1 = macro_f1\n",
    "                        best_sig_thr = float(thr_sig)\n",
    "                        best_thr_down = float(thr_down)\n",
    "                        best_thr_up = float(thr_up)\n",
    "                        best_trade_rate = trade_rate\n",
    "                        best_counts = {'signal': n_signal, 'trades': n_trades, 'up': n_up, 'down': n_down}\n",
    "\n",
    "    SIG_THR_TRADE = float(best_sig_thr)\n",
    "    DIR_THR_DOWN = float(best_thr_down)\n",
    "    DIR_THR_UP = float(best_thr_up)\n",
    "    print('[opt] THRESH_OPT_OBJECTIVE:', THRESH_OPT_OBJECTIVE)\n",
    "    print('[opt] TUNE_SPLIT:', TUNE_SPLIT)\n",
    "    print('[opt] SIG_THR_TRADE:', SIG_THR_TRADE, 'DIR_THR_DOWN/UP:', DIR_THR_DOWN, DIR_THR_UP)\n",
    "    print('[opt] score:', best_score, f\"pnl({TUNE_SPLIT}):\", best_pnl, f\"macro_f1({TUNE_SPLIT}):\", best_macro_f1)\n",
    "    print('[opt] trade_rate:', best_trade_rate, 'counts:', best_counts)\n",
    "# Kombinierte 3-Klassen-Auswertung auf Test\n",
    "X_test_all = splits['test'][feature_cols]\n",
    "signal_prob_test = proba_pos(model_signal, X_test_all)\n",
    "signal_pred_test = (signal_prob_test >= SIGNAL_THRESHOLD).astype(int)\n",
    "dir_prob_test = proba_pos(model_dir, X_test_all)\n",
    "\n",
    "combined_pred = np.full(len(signal_prob_test), 'neutral', dtype=object)\n",
    "mask_signal_trade = signal_prob_test >= SIG_THR_TRADE\n",
    "if not ALLOW_DIRECTION_NEUTRAL:\n",
    "    # Keine Neutral-Zone: >= thr => up, < thr => down (equals geht nach up)\n",
    "    combined_pred[mask_signal_trade & (dir_prob_test >= DIR_THR_UP)] = 'up'\n",
    "    combined_pred[mask_signal_trade & (dir_prob_test <  DIR_THR_UP)] = 'down'\n",
    "else:\n",
    "    combined_pred[mask_signal_trade & (dir_prob_test >= DIR_THR_UP)] = 'up'\n",
    "    combined_pred[mask_signal_trade & (dir_prob_test <= DIR_THR_DOWN)] = 'down'\n",
    "\n",
    "combined_true = splits['test']['label'].to_numpy()\n",
    "\n",
    "combined_report = classification_report(\n",
    "    combined_true,\n",
    "    combined_pred,\n",
    "    labels=['neutral', 'up', 'down'],\n",
    "    output_dict=True,\n",
    "    digits=3,\n",
    ")\n",
    "combined_cm = confusion_matrix(\n",
    "    combined_true,\n",
    "    combined_pred,\n",
    "    labels=['neutral', 'up', 'down'],\n",
    ").tolist()\n",
    "\n",
    "# Optional: 3-Klassen-Baseline (ein Modell statt Two-Stage)\n",
    "multiclass_metrics = None\n",
    "multiclass_params = None\n",
    "if TRAIN_MULTICLASS_BASELINE:\n",
    "    import xgboost as xgb\n",
    "    label_map_mc = {'neutral': 0, 'up': 1, 'down': 2}\n",
    "\n",
    "    def _y_mc(split_name: str):\n",
    "        return splits[split_name]['label'].map(label_map_mc).astype(int).to_numpy()\n",
    "\n",
    "    y_train_mc = _y_mc('train')\n",
    "    y_val_mc = _y_mc('val')\n",
    "    y_test_mc = _y_mc('test')\n",
    "\n",
    "    # Inverse Klassenhäufigkeit als Sample-Weights\n",
    "    counts = np.bincount(y_train_mc, minlength=3)\n",
    "    total = float(len(y_train_mc))\n",
    "    cls_w = {i: (total / (3.0 * max(float(c), 1.0))) for i, c in enumerate(counts)}\n",
    "    w_train_mc = np.array([cls_w[int(y)] for y in y_train_mc], dtype=float)\n",
    "    print('[mc] class counts train:', {i: int(c) for i, c in enumerate(counts)}, 'weights:', cls_w)\n",
    "\n",
    "    model_mc = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=3,\n",
    "        eval_metric='mlogloss',\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=600,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "    )\n",
    "    # Features: wie Signal-Modell (alle Tage)\n",
    "    use_eval_mc = X_val_signal is not None and len(X_val_signal) > 0 and y_val_mc is not None and len(y_val_mc) > 0\n",
    "    if use_eval_mc:\n",
    "        model_mc.fit(\n",
    "            X_train_signal,\n",
    "            y_train_mc,\n",
    "            sample_weight=w_train_mc,\n",
    "            eval_set=[(X_val_signal, y_val_mc)],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False,\n",
    "        )\n",
    "    else:\n",
    "        # Kein Val-Split verfügbar -> ohne Early-Stopping trainieren\n",
    "        model_mc.fit(\n",
    "            X_train_signal,\n",
    "            y_train_mc,\n",
    "            sample_weight=w_train_mc,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    def _mc_metrics(y_true, y_pred):\n",
    "        if y_true is None or len(y_true) == 0:\n",
    "            return {'report': {}, 'confusion_matrix': []}\n",
    "        rep = classification_report(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            target_names=['neutral', 'up', 'down'],\n",
    "            output_dict=True,\n",
    "            digits=3,\n",
    "            zero_division=0,\n",
    "        )\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2]).tolist()\n",
    "        return {'report': rep, 'confusion_matrix': cm}\n",
    "\n",
    "    pred_train_mc = model_mc.predict(X_train_signal)\n",
    "    pred_val_mc = model_mc.predict(X_val_signal) if X_val_signal is not None and len(X_val_signal) > 0 else np.array([], dtype=int)\n",
    "    pred_test_mc = model_mc.predict(X_test_signal) if X_test_signal is not None and len(X_test_signal) > 0 else np.array([], dtype=int)\n",
    "\n",
    "    multiclass_metrics = {\n",
    "        'train': _mc_metrics(y_train_mc, pred_train_mc),\n",
    "        'val': _mc_metrics(y_val_mc, pred_val_mc),\n",
    "        'test': _mc_metrics(y_test_mc, pred_test_mc),\n",
    "        'labels': ['neutral', 'up', 'down'],\n",
    "    }\n",
    "    multiclass_params = model_mc.get_xgb_params()\n",
    "    multiclass_params['feature_importances_'] = model_mc.feature_importances_.tolist()\n",
    "    print('[ok] 3-Klassen-Baseline trainiert.')\n",
    "\n",
    "# Modell-Parameter + Feature-Importances\n",
    "signal_params = model_signal.get_xgb_params()\n",
    "direction_params = model_dir.get_xgb_params()\n",
    "signal_params['feature_importances_'] = model_signal.feature_importances_.tolist()\n",
    "direction_params['feature_importances_'] = model_dir.feature_importances_.tolist()\n",
    "\n",
    "# Config laden\n",
    "from src.utils.io import DATA_PROCESSED\n",
    "exp_meta_dir = DATA_PROCESSED / 'experiments'\n",
    "exp_config_path = exp_meta_dir / f'{EXP_ID}_config.json'\n",
    "if 'exp_config' not in globals():\n",
    "    with exp_config_path.open('r', encoding='utf-8') as f:\n",
    "        exp_config = json.load(f)\n",
    "\n",
    "feature_mode = FEATURE_MODE\n",
    "\n",
    "config_block = {\n",
    "    'exp_id': exp_config.get('exp_id', EXP_ID),\n",
    "    'price_source': exp_config.get('label_params', {}).get('price_source'),\n",
    "    'drop_weekends': exp_config.get('label_params', {}).get('drop_weekends'),\n",
    "    'horizon_days': exp_config.get('label_params', {}).get('horizon_days'),\n",
    "    'up_threshold': exp_config.get('label_params', {}).get('up_threshold'),\n",
    "    'down_threshold': exp_config.get('label_params', {}).get('down_threshold'),\n",
    "    'strict_monotonic': exp_config.get('label_params', {}).get('strict_monotonic'),\n",
    "    'max_adverse_move_pct': exp_config.get('label_params', {}).get('max_adverse_move_pct'),\n",
    "    'hit_within_horizon': exp_config.get('label_params', {}).get('hit_within_horizon'),\n",
    "    'first_hit_wins': exp_config.get('label_params', {}).get('first_hit_wins'),\n",
    "    'dataset_path': str(ds_path),\n",
    "    'feature_cols': feature_cols,\n",
    "    'test_start': test_start,\n",
    "    'train_frac_within_pretest': train_frac_pretest,\n",
    "    'use_validation': bool(USE_VALIDATION),\n",
    "    'tune_thresholds_on': str(TUNE_THRESHOLDS_ON),\n",
    "    'signal_threshold': SIGNAL_THRESHOLD,\n",
    "    'signal_threshold_trade': SIG_THR_TRADE,\n",
    "    'direction_threshold': DIR_THRESHOLD,\n",
    "    'direction_threshold_down': DIR_THR_DOWN,\n",
    "    'direction_threshold_up': DIR_THR_UP,\n",
    "    'allow_direction_neutral': bool(ALLOW_DIRECTION_NEUTRAL),\n",
    "    'threshold_opt_objective': THRESH_OPT_OBJECTIVE,\n",
    "    'threshold_tune_split': str(TUNE_SPLIT),\n",
    "    'use_fixed_thresholds': bool(USE_FIXED_THRESHOLDS),\n",
    "    'fixed_signal_trade_threshold': float(FIXED_SIGNAL_TRADE_THRESHOLD),\n",
    "    'fixed_dir_threshold': float(FIXED_DIR_THRESHOLD),\n",
    "    'fixed_dir_threshold_down': float(FIXED_DIR_THRESHOLD_DOWN),\n",
    "    'fixed_dir_threshold_up': float(FIXED_DIR_THRESHOLD_UP),\n",
    "    'trade_profile': str(TRADE_PROFILE),\n",
    "    'auto_fixed_dir_thresholds': bool(AUTO_FIXED_DIR_THRESHOLDS),\n",
    "    'fixed_dir_q_down': float(FIXED_DIR_Q_DOWN),\n",
    "    'fixed_dir_q_up': float(FIXED_DIR_Q_UP),\n",
    "    'min_dir_gap': float(MIN_DIR_GAP),\n",
    "    'target_trade_rate': TARGET_TRADE_RATE,\n",
    "    'trade_rate_penalty': float(TRADE_RATE_PENALTY),\n",
    "    'train_multiclass_baseline': bool(TRAIN_MULTICLASS_BASELINE),\n",
    "    'signal_xgb_params': SIGNAL_XGB_PARAMS,\n",
    "    'direction_xgb_params': DIRECTION_XGB_PARAMS,\n",
    "    'feature_mode': feature_mode,\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'config': config_block,\n",
    "    'model_params': {\n",
    "        'signal': signal_params,\n",
    "        'direction': direction_params,\n",
    "    },\n",
    "    'signal': signal_metrics,\n",
    "    'direction': direction_metrics,\n",
    "    'combined_test': {\n",
    "        'report': combined_report,\n",
    "        'confusion_matrix': combined_cm,\n",
    "        'labels': ['neutral', 'up', 'down'],\n",
    "    },\n",
    "}\n",
    "if multiclass_metrics is not None:\n",
    "    results['multiclass'] = multiclass_metrics\n",
    "    results['model_params']['multiclass'] = multiclass_params\n",
    "\n",
    "# Ergebnisse in Standard- und Final-Ordner schreiben\n",
    "base_results_dir = Path('notebooks') / 'results'\n",
    "final_results_dir = base_results_dir / 'final_two_stage'\n",
    "base_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "final_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "json_base = base_results_dir / f'two_stage__{EXP_ID}.json'\n",
    "json_final = final_results_dir / f'two_stage_final__{EXP_ID}.json'\n",
    "\n",
    "with json_base.open('w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "with json_final.open('w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# einfache Metrik-Tabelle (F1 der positiven Klasse)\n",
    "rows = []\n",
    "for model_key, model_name, pos_label in [\n",
    "    ('signal', 'signal', 'move'),\n",
    "    ('direction', 'direction', 'up'),\n",
    "]:\n",
    "    metrics = results[model_key]\n",
    "    for split, m in metrics.items():\n",
    "        rep = m['report']\n",
    "        cls = rep.get(pos_label, {})\n",
    "        rows.append({\n",
    "            'model': model_name,\n",
    "            'split': split,\n",
    "            'precision_pos': cls.get('precision'),\n",
    "            'recall_pos': cls.get('recall'),\n",
    "            'f1_pos': cls.get('f1-score'),\n",
    "        })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "csv_final = final_results_dir / f'two_stage_final__{EXP_ID}_metrics.csv'\n",
    "metrics_df.to_csv(csv_final, index=False)\n",
    "\n",
    "# Test-Predictions als CSV für Fehlklassifikations-Analysen speichern\n",
    "test_dates = splits['test']['date'].to_numpy()\n",
    "test_labels = splits['test']['label'].to_numpy()\n",
    "\n",
    "# Optional: 3-Klassen-Baseline-Predictions (falls TRAIN_MULTICLASS_BASELINE=True)\n",
    "mc_pred_test = None\n",
    "mc_proba_test = None\n",
    "if TRAIN_MULTICLASS_BASELINE:\n",
    "    inv = {0: 'neutral', 1: 'up', 2: 'down'}\n",
    "    mc_pred_test = np.array([inv[int(i)] for i in pred_test_mc], dtype=object)\n",
    "    mc_proba_test = model_mc.predict_proba(X_test_signal)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    'date': test_dates,\n",
    "    'label_true': test_labels,\n",
    "    'signal_prob': signal_prob_test.astype(float),\n",
    "    'signal_pred': signal_pred_test.astype(int),\n",
    "    'direction_prob_up': dir_prob_test.astype(float),\n",
    "    'direction_pred_up': np.where(combined_pred == 'up', 1, np.where(combined_pred == 'down', 0, -1)).astype(int),\n",
    "    'combined_pred': combined_pred,\n",
    "})\n",
    "\n",
    "if mc_pred_test is not None and mc_proba_test is not None and len(mc_proba_test) == len(pred_df):\n",
    "    pred_df['multiclass_pred'] = mc_pred_test\n",
    "    pred_df['multiclass_prob_neutral'] = mc_proba_test[:, 0].astype(float)\n",
    "    pred_df['multiclass_prob_up'] = mc_proba_test[:, 1].astype(float)\n",
    "    pred_df['multiclass_prob_down'] = mc_proba_test[:, 2].astype(float)\n",
    "\n",
    "pred_path = final_results_dir / f'two_stage_final__{EXP_ID}_predictions.csv'\n",
    "pred_df.to_csv(pred_path, index=False)\n",
    "\n",
    "print('[ok] Ergebnisse gespeichert unter:')\n",
    "print('   JSON base :', json_base)\n",
    "print('   JSON final:', json_final)\n",
    "print('   CSV final :', csv_final)\n",
    "print('   Predictions:', pred_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
