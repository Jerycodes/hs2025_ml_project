{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2 – Training (Final)\n",
        "\n",
        "Dieses Notebook trainiert für eine gegebene `EXP_ID` das Zwei-Stufen-\n",
        "XGBoost-Modell (Signal + Richtung). Es liest die Config und den\n",
        "Trainingsdatensatz aus `data/processed/...` und erzeugt nur den\n",
        "Modell-Fit und einfache Metriken.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0bb97ab7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erkannte Projektwurzel: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n",
            "Arbeitsverzeichnis gesetzt auf: /Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "cwd = Path.cwd()\n",
        "project_root = cwd\n",
        "while not (project_root / 'src').is_dir():\n",
        "    if project_root.parent == project_root:\n",
        "        raise RuntimeError(\"Projektwurzel mit 'src' nicht gefunden.\")\n",
        "    project_root = project_root.parent\n",
        "\n",
        "print('Erkannte Projektwurzel:', project_root)\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.append(str(project_root))\n",
        "\n",
        "os.chdir(project_root)\n",
        "print('Arbeitsverzeichnis gesetzt auf:', Path.cwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51a56970",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bitte EXP_ID explizit setzen, passend zur Data-Prep.\n",
        "EXP_ID = 'hv5_h4_thr0p4pct_hit_6_2'  # z.B. 'v3_h4_thr0p3pct_relaxed'\n",
        "assert EXP_ID != 'CHANGE_ME', 'Bitte EXP_ID oben setzen.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "341e4c15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verwende Datensatz: data/processed/datasets/eurusd_news_training__hv5_h4_thr0p4pct_hit_6_2.csv\n",
            "(1163, 44)\n",
            "Feature-Spalten: 35\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from src.utils.io import DATA_PROCESSED\n",
        "from src.models.train_xgboost_two_stage import (\n",
        "    split_train_val_test,\n",
        "    build_signal_targets,\n",
        "    build_direction_targets,\n",
        "    train_xgb_binary,\n",
        "    get_feature_cols,\n",
        ")\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "# Datensatz laden\n",
        "ds_path = DATA_PROCESSED / 'datasets' / f'eurusd_news_training__{EXP_ID}.csv'\n",
        "print('Verwende Datensatz:', ds_path)\n",
        "df = pd.read_csv(ds_path, parse_dates=['date']).sort_values('date').reset_index(drop=True)\n",
        "print(df.shape)\n",
        "feature_cols = get_feature_cols(df)\n",
        "\n",
        "# Optionaler Price-only-Baseline-Modus: EXP_ID beginnt mit 'hp'.\n",
        "if EXP_ID.startswith('hp'):\n",
        "    drop_prefixes = ['news_']\n",
        "    drop_exact = [\n",
        "        'article_count',\n",
        "        'avg_polarity',\n",
        "        'avg_neg',\n",
        "        'avg_neu',\n",
        "        'avg_pos',\n",
        "        'pos_share',\n",
        "        'neg_share',\n",
        "    ]\n",
        "    feature_cols = [\n",
        "        c\n",
        "        for c in feature_cols\n",
        "        if not any(c.startswith(p) for p in drop_prefixes) and c not in drop_exact\n",
        "    ]\n",
        "    print('[info] Price-only Baseline aktiv – News-Features entfernt.')\n",
        "\n",
        "print('Feature-Spalten:', len(feature_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1767994a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 2020-04-14 -> 2024-04-09 n= 756\n",
            "val 2024-04-10 -> 2024-12-31 n= 189\n",
            "test 2025-01-02 -> 2025-11-05 n= 218\n"
          ]
        }
      ],
      "source": [
        "# Zeitliche Splits\n",
        "test_start = '2025-01-01'\n",
        "train_frac_pretest = 0.8\n",
        "\n",
        "splits = split_train_val_test(\n",
        "    df, pd.to_datetime(test_start), train_frac_within_pretest=train_frac_pretest\n",
        ")\n",
        "for name, split_df in splits.items():\n",
        "    print(name, split_df['date'].min().date(), '->', split_df['date'].max().date(), 'n=', len(split_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5d06f176",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Signal scale_pos_weight: 0.18309859154929578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ok] Signal-Modell trainiert.\n",
            "[ok] Richtungs-Modell trainiert.\n",
            "Richtungs-Schwelle (val-basiert): 0.4 F1_up(val): 0.7341772151898734\n",
            "Richtungs-Schwellen (kostenbasiert, Val): 0.3 0.625 P&L(val): 0.5999999999999992\n",
            "Signal-Schwelle (kostenbasiert, Val): 0.7 P&L(val): 7.20000000000001\n",
            "[ok] Ergebnisse gespeichert unter:\n",
            "   JSON base : notebooks/results/two_stage__hv5_h4_thr0p4pct_hit_6_2.json\n",
            "   JSON final: notebooks/results/final_two_stage/two_stage_final__hv5_h4_thr0p4pct_hit_6_2.json\n",
            "   CSV final : notebooks/results/final_two_stage/two_stage_final__hv5_h4_thr0p4pct_hit_6_2_metrics.csv\n",
            "   Predictions: notebooks/results/final_two_stage/two_stage_final__hv5_h4_thr0p4pct_hit_6_2_predictions.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeremynathan/Documents/GitHub/hs2025_ml_project/hs2025_ml_project/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import json\n",
        "\n",
        "# Schwelle für das Signal-Modell (Stufe 1).\n",
        "# Höhere Werte -> höhere Precision, geringerer Recall.\n",
        "SIGNAL_THRESHOLD = 0.5\n",
        "\n",
        "# --- Signal-Modell trainieren ---\n",
        "y_train_signal = build_signal_targets(splits['train'])\n",
        "y_val_signal   = build_signal_targets(splits['val'])\n",
        "y_test_signal  = build_signal_targets(splits['test'])\n",
        "\n",
        "X_train_signal = splits['train'][feature_cols]\n",
        "X_val_signal   = splits['val'][feature_cols]\n",
        "X_test_signal  = splits['test'][feature_cols]\n",
        "\n",
        "# Class-Imbalance für das Signal-Modell explizit berücksichtigen\n",
        "n_pos_signal = int((y_train_signal == 1).sum())\n",
        "n_neg_signal = int((y_train_signal == 0).sum())\n",
        "scale_pos_weight_signal = n_neg_signal / max(n_pos_signal, 1)\n",
        "print('Signal scale_pos_weight:', scale_pos_weight_signal)\n",
        "\n",
        "model_signal = train_xgb_binary(\n",
        "    X_train_signal,\n",
        "    y_train_signal,\n",
        "    X_val_signal,\n",
        "    y_val_signal,\n",
        "    scale_pos_weight=scale_pos_weight_signal,\n",
        ")\n",
        "print('[ok] Signal-Modell trainiert.')\n",
        "\n",
        "# --- Richtungs-Modell trainieren ---\n",
        "X_train_dir, y_train_dir = build_direction_targets(splits['train'], feature_cols=feature_cols)\n",
        "X_val_dir,   y_val_dir   = build_direction_targets(splits['val'],   feature_cols=feature_cols)\n",
        "X_test_dir,  y_test_dir  = build_direction_targets(splits['test'],  feature_cols=feature_cols)\n",
        "\n",
        "model_dir = train_xgb_binary(\n",
        "    X_train_dir,\n",
        "    y_train_dir,\n",
        "    X_val_dir,\n",
        "    y_val_dir,\n",
        "    scale_pos_weight=1.0,\n",
        ")\n",
        "print('[ok] Richtungs-Modell trainiert.')\n",
        "\n",
        "# --- Metriken berechnen und speichern ---\n",
        "\n",
        "def binary_metrics_dict(y_true, y_prob, threshold, target_names):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "    report = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        target_names=target_names,\n",
        "        output_dict=True,\n",
        "        digits=3,\n",
        "    )\n",
        "    cm = confusion_matrix(y_true, y_pred).tolist()\n",
        "    return {\n",
        "        'threshold': float(threshold),\n",
        "        'report': report,\n",
        "        'confusion_matrix': cm,\n",
        "    }\n",
        "\n",
        "# Wahrscheinlichkeiten\n",
        "p_train_signal = model_signal.predict_proba(X_train_signal)[:, 1]\n",
        "p_val_signal   = model_signal.predict_proba(X_val_signal)[:, 1]\n",
        "p_test_signal  = model_signal.predict_proba(X_test_signal)[:, 1]\n",
        "\n",
        "signal_metrics = {\n",
        "    'train': binary_metrics_dict(y_train_signal, p_train_signal, SIGNAL_THRESHOLD, ['neutral', 'move']),\n",
        "    'val':   binary_metrics_dict(y_val_signal,   p_val_signal,   SIGNAL_THRESHOLD, ['neutral', 'move']),\n",
        "    'test':  binary_metrics_dict(y_test_signal,  p_test_signal,  SIGNAL_THRESHOLD, ['neutral', 'move']),\n",
        "}\n",
        "\n",
        "p_train_dir = model_dir.predict_proba(X_train_dir)[:, 1]\n",
        "p_val_dir   = model_dir.predict_proba(X_val_dir)[:, 1]\n",
        "p_test_dir  = model_dir.predict_proba(X_test_dir)[:, 1]\n",
        "\n",
        "# Threshold für das Richtungs-Modell (down vs up) anhand des Val-Splits optimieren\n",
        "thr_grid = np.linspace(0.4, 0.6, 11)\n",
        "best_thr = 0.5\n",
        "best_f1_up = -1.0\n",
        "for thr in thr_grid:\n",
        "    y_val_pred = (p_val_dir >= thr).astype(int)\n",
        "    rep = classification_report(\n",
        "        y_val_dir,\n",
        "        y_val_pred,\n",
        "        target_names=['down', 'up'],\n",
        "        output_dict=True,\n",
        "        digits=3,\n",
        "    )\n",
        "    f1_up = rep['up']['f1-score']\n",
        "    if f1_up > best_f1_up:\n",
        "        best_f1_up = f1_up\n",
        "        best_thr = thr\n",
        "\n",
        "DIR_THRESHOLD = float(best_thr)\n",
        "print('Richtungs-Schwelle (val-basiert):', DIR_THRESHOLD, 'F1_up(val):', best_f1_up)\n",
        "\n",
        "direction_metrics = {\n",
        "    'train': binary_metrics_dict(y_train_dir, p_train_dir, DIR_THRESHOLD, ['down', 'up']),\n",
        "    'val':   binary_metrics_dict(y_val_dir,   p_val_dir,   DIR_THRESHOLD, ['down', 'up']),\n",
        "    'test':  binary_metrics_dict(y_test_dir,  p_test_dir,  DIR_THRESHOLD, ['down', 'up']),\n",
        "}\n",
        "\n",
        "# --- Kostenbasierte Schwellen für das Richtungs-Modell bestimmen ---\n",
        "from src.utils.io import DATA_PROCESSED  # für Zugriff auf Experiment-Config\n",
        "exp_meta_dir = DATA_PROCESSED / 'experiments'\n",
        "exp_config_path = exp_meta_dir / f'{EXP_ID}_config.json'\n",
        "with exp_config_path.open('r', encoding='utf-8') as f:\n",
        "    _cfg = json.load(f)\n",
        "label_params = _cfg.get('label_params', {})\n",
        "up_thr_label = float(label_params.get('up_threshold', 0.0))\n",
        "down_thr_label = float(label_params.get('down_threshold', 0.0))\n",
        "max_adv_label = label_params.get('max_adverse_move_pct', 0.01) or 0.01\n",
        "\n",
        "# Einsatz-Größen für die Kostenfunktion (müssen zu Strategie A im Report passen)\n",
        "stake_up = 100.0\n",
        "stake_down = 100.0\n",
        "\n",
        "def cost_per_trade(true_label: str, pred_label: str) -> float:\n",
        "    \"\"\"Approx. Trade-Kosten in CHF für Strategie A.\n",
        "\n",
        "    Vereinfachte Annahme:\n",
        "    - Korrekte Trades verdienen ca. Schwelle * Einsatz.\n",
        "    - Falsche Trades bzw. Trades auf neutralen Tagen verlieren ca.\n",
        "      max_adverse_move_pct * Einsatz.\n",
        "    \"\"\"\n",
        "    true_label = str(true_label)\n",
        "    pred_label = str(pred_label)\n",
        "\n",
        "    if pred_label == 'neutral':\n",
        "        return 0.0\n",
        "    if true_label == 'neutral':\n",
        "        # konservativ: immer Stop-Loss\n",
        "        return -stake_up * max_adv_label if pred_label == 'up' else -stake_down * max_adv_label\n",
        "    if pred_label == 'up':\n",
        "        if true_label == 'up':\n",
        "            return stake_up * up_thr_label\n",
        "        else:  # true_label == 'down'\n",
        "            return -stake_up * max_adv_label\n",
        "    if pred_label == 'down':\n",
        "        if true_label == 'down':\n",
        "            return stake_down * (-down_thr_label)\n",
        "        else:  # true_label == 'up'\n",
        "            return -stake_down * max_adv_label\n",
        "    return 0.0\n",
        "\n",
        "labels_val = splits['val']['label'].to_numpy()\n",
        "signal_pred_val = (p_val_signal >= SIGNAL_THRESHOLD).astype(int)\n",
        "p_val_dir_all = model_dir.predict_proba(splits['val'][feature_cols])[:, 1]\n",
        "\n",
        "thr_candidates = np.linspace(0.3, 0.7, 17)\n",
        "best_pnl = -1e18\n",
        "best_thr_down = 0.4\n",
        "best_thr_up = 0.6\n",
        "\n",
        "for thr_down in thr_candidates:\n",
        "    for thr_up in thr_candidates:\n",
        "        if thr_down >= thr_up:\n",
        "            continue\n",
        "        pnl = 0.0\n",
        "        for prob, sig, true_lab in zip(p_val_dir_all, signal_pred_val, labels_val):\n",
        "            if sig == 0:\n",
        "                continue  # kein Trade, wenn Stufe 1 schon neutral ist\n",
        "            if prob >= thr_up:\n",
        "                pred_label = 'up'\n",
        "            elif prob <= thr_down:\n",
        "                pred_label = 'down'\n",
        "            else:\n",
        "                pred_label = 'neutral'\n",
        "            pnl += cost_per_trade(true_lab, pred_label)\n",
        "        if pnl > best_pnl:\n",
        "            best_pnl = pnl\n",
        "            best_thr_down = thr_down\n",
        "            best_thr_up = thr_up\n",
        "\n",
        "DIR_THR_DOWN = float(best_thr_down)\n",
        "DIR_THR_UP = float(best_thr_up)\n",
        "print('Richtungs-Schwellen (kostenbasiert, Val):', DIR_THR_DOWN, DIR_THR_UP, 'P&L(val):', best_pnl)\n",
        "\n",
        "# --- Kostenbasierte Schwelle für das Signal-Modell bestimmen ---\n",
        "thr_sig_candidates = np.linspace(0.3, 0.7, 17)\n",
        "best_sig_thr = SIGNAL_THRESHOLD\n",
        "best_sig_pnl = -1e18\n",
        "for thr_sig in thr_sig_candidates:\n",
        "    pnl = 0.0\n",
        "    for sig_prob, dir_prob, true_lab in zip(p_val_signal, p_val_dir_all, labels_val):\n",
        "        if sig_prob < thr_sig:\n",
        "            pred_label = 'neutral'\n",
        "        else:\n",
        "            if dir_prob >= DIR_THR_UP:\n",
        "                pred_label = 'up'\n",
        "            elif dir_prob <= DIR_THR_DOWN:\n",
        "                pred_label = 'down'\n",
        "            else:\n",
        "                pred_label = 'neutral'\n",
        "        pnl += cost_per_trade(true_lab, pred_label)\n",
        "    if pnl > best_sig_pnl:\n",
        "        best_sig_pnl = pnl\n",
        "        best_sig_thr = thr_sig\n",
        "\n",
        "SIG_THR_TRADE = float(best_sig_thr)\n",
        "print('Signal-Schwelle (kostenbasiert, Val):', SIG_THR_TRADE, 'P&L(val):', best_sig_pnl)\n",
        "\n",
        "# Kombinierte 3-Klassen-Auswertung auf Test\n",
        "X_test_all = splits['test'][feature_cols]\n",
        "signal_prob_test = model_signal.predict_proba(X_test_all)[:, 1]\n",
        "signal_pred_test = (signal_prob_test >= SIGNAL_THRESHOLD).astype(int)\n",
        "dir_prob_test = model_dir.predict_proba(X_test_all)[:, 1]\n",
        "\n",
        "combined_pred = np.full(len(signal_prob_test), 'neutral', dtype=object)\n",
        "mask_signal_trade = signal_prob_test >= SIG_THR_TRADE\n",
        "combined_pred[mask_signal_trade & (dir_prob_test >= DIR_THR_UP)] = 'up'\n",
        "combined_pred[mask_signal_trade & (dir_prob_test <= DIR_THR_DOWN)] = 'down'\n",
        "\n",
        "combined_true = splits['test']['label'].to_numpy()\n",
        "\n",
        "combined_report = classification_report(\n",
        "    combined_true,\n",
        "    combined_pred,\n",
        "    labels=['neutral', 'up', 'down'],\n",
        "    output_dict=True,\n",
        "    digits=3,\n",
        ")\n",
        "combined_cm = confusion_matrix(\n",
        "    combined_true,\n",
        "    combined_pred,\n",
        "    labels=['neutral', 'up', 'down'],\n",
        ").tolist()\n",
        "\n",
        "# Modell-Parameter + Feature-Importances\n",
        "signal_params = model_signal.get_xgb_params()\n",
        "direction_params = model_dir.get_xgb_params()\n",
        "signal_params['feature_importances_'] = model_signal.feature_importances_.tolist()\n",
        "direction_params['feature_importances_'] = model_dir.feature_importances_.tolist()\n",
        "\n",
        "# Config laden\n",
        "from src.utils.io import DATA_PROCESSED\n",
        "exp_meta_dir = DATA_PROCESSED / 'experiments'\n",
        "exp_config_path = exp_meta_dir / f'{EXP_ID}_config.json'\n",
        "with exp_config_path.open('r', encoding='utf-8') as f:\n",
        "    exp_config = json.load(f)\n",
        "\n",
        "feature_mode = 'price_only' if EXP_ID.startswith('hp') else 'news+price'\n",
        "\n",
        "config_block = {\n",
        "    'exp_id': exp_config.get('exp_id', EXP_ID),\n",
        "    'horizon_days': exp_config.get('label_params', {}).get('horizon_days'),\n",
        "    'up_threshold': exp_config.get('label_params', {}).get('up_threshold'),\n",
        "    'down_threshold': exp_config.get('label_params', {}).get('down_threshold'),\n",
        "    'strict_monotonic': exp_config.get('label_params', {}).get('strict_monotonic'),\n",
        "    'dataset_path': str(ds_path),\n",
        "    'feature_cols': feature_cols,\n",
        "    'test_start': test_start,\n",
        "    'train_frac_within_pretest': train_frac_pretest,\n",
        "    'signal_threshold': SIGNAL_THRESHOLD,\n",
        "    'signal_threshold_trade': SIG_THR_TRADE,\n",
        "    'direction_threshold': DIR_THRESHOLD,\n",
        "    'direction_threshold_down': DIR_THR_DOWN,\n",
        "    'direction_threshold_up': DIR_THR_UP,\n",
        "    'feature_mode': feature_mode,\n",
        "}\n",
        "\n",
        "results = {\n",
        "    'config': config_block,\n",
        "    'model_params': {\n",
        "        'signal': signal_params,\n",
        "        'direction': direction_params,\n",
        "    },\n",
        "    'signal': signal_metrics,\n",
        "    'direction': direction_metrics,\n",
        "    'combined_test': {\n",
        "        'report': combined_report,\n",
        "        'confusion_matrix': combined_cm,\n",
        "        'labels': ['neutral', 'up', 'down'],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Ergebnisse in Standard- und Final-Ordner schreiben\n",
        "base_results_dir = Path('notebooks') / 'results'\n",
        "final_results_dir = base_results_dir / 'final_two_stage'\n",
        "base_results_dir.mkdir(parents=True, exist_ok=True)\n",
        "final_results_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "json_base = base_results_dir / f'two_stage__{EXP_ID}.json'\n",
        "json_final = final_results_dir / f'two_stage_final__{EXP_ID}.json'\n",
        "\n",
        "with json_base.open('w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "with json_final.open('w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# einfache Metrik-Tabelle (F1 der positiven Klasse)\n",
        "rows = []\n",
        "for model_key, model_name, pos_label in [\n",
        "    ('signal', 'signal', 'move'),\n",
        "    ('direction', 'direction', 'up'),\n",
        "]:\n",
        "    metrics = results[model_key]\n",
        "    for split, m in metrics.items():\n",
        "        rep = m['report']\n",
        "        cls = rep.get(pos_label, {})\n",
        "        rows.append({\n",
        "            'model': model_name,\n",
        "            'split': split,\n",
        "            'precision_pos': cls.get('precision'),\n",
        "            'recall_pos': cls.get('recall'),\n",
        "            'f1_pos': cls.get('f1-score'),\n",
        "        })\n",
        "\n",
        "metrics_df = pd.DataFrame(rows)\n",
        "csv_final = final_results_dir / f'two_stage_final__{EXP_ID}_metrics.csv'\n",
        "metrics_df.to_csv(csv_final, index=False)\n",
        "\n",
        "# Test-Predictions als CSV für Fehlklassifikations-Analysen speichern\n",
        "test_dates = splits['test']['date'].to_numpy()\n",
        "test_labels = splits['test']['label'].to_numpy()\n",
        "\n",
        "pred_rows = []\n",
        "for dt, y_true, sig_p, sig_hat, dir_p, comb_hat in zip(\n",
        "    test_dates,\n",
        "    test_labels,\n",
        "    signal_prob_test,\n",
        "    signal_pred_test,\n",
        "    dir_prob_test,\n",
        "    combined_pred,\n",
        "):\n",
        "    pred_rows.append({\n",
        "        'date': dt,\n",
        "        'label_true': y_true,\n",
        "        'signal_prob': float(sig_p),\n",
        "        'signal_pred': int(sig_hat),\n",
        "        'direction_prob_up': float(dir_p),\n",
        "        'direction_pred_up': 1 if comb_hat == 'up' else (0 if comb_hat == 'down' else -1),\n",
        "        'combined_pred': comb_hat,\n",
        "    })\n",
        "\n",
        "pred_df = pd.DataFrame(pred_rows)\n",
        "pred_path = final_results_dir / f'two_stage_final__{EXP_ID}_predictions.csv'\n",
        "pred_df.to_csv(pred_path, index=False)\n",
        "\n",
        "print('[ok] Ergebnisse gespeichert unter:')\n",
        "print('   JSON base :', json_base)\n",
        "print('   JSON final:', json_final)\n",
        "print('   CSV final :', csv_final)\n",
        "print('   Predictions:', pred_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
