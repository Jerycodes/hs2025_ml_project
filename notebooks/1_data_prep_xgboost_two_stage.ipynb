{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zwei-Stufen-XGBoost – Experimentsteuerung\n",
    "\n",
    "In diesem Notebook möchte ich Experimente so aufsetzen, dass **alle Daten und Ergebnisse automatisch\n",
    "mit einer Experiment-ID versioniert werden**.\n",
    "\n",
    "Grundidee:\n",
    "\n",
    "- Ich definiere am Anfang eine `EXP_ID` (z.\\u00a0B. `v1_h4_thr0p5pct_strict`).\n",
    "- Daraus werden automatisch erzeugt:\n",
    "  - `data/processed/fx/eurusd_labels__<EXP_ID>.csv`\n",
    "  - `data/processed/datasets/eurusd_news_training__<EXP_ID>.csv`\n",
    "  - sowie jeweils die aktuelle Version ohne Suffix (`..._latest`).\n",
    "- Sp\\u00e4tere Modell-Notebooks k\\u00f6nnen diese Dateien direkt verwenden und Ergebnisse als\n",
    "  `notebooks/results/two_stage__<EXP_ID>.json` speichern.\n",
    "\n",
    "Damit ist jederzeit klar dokumentiert, **mit welchen Label-Parametern und Features ein Experiment\n",
    "durchgef\\u00fchrt wurde**, und ich kann sp\\u00e4ter leicht vergleichen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Aktuelles Arbeitsverzeichnis des Kernels ermitteln.\n",
    "# In VS Code ist das normalerweise der Projektordner `hs2025_ml_project/hs2025_ml_project`.\n",
    "cwd = Path.cwd()\n",
    "print(\"Aktuelles Arbeitsverzeichnis:\", cwd)\n",
    "\n",
    "# Projektwurzel automatisch finden, indem wir nach oben laufen, bis ein Ordner `src` existiert.\n",
    "# So funktioniert das Notebook auch dann, wenn es in einem Unterordner wie `notebooks/` liegt.\n",
    "project_root = cwd\n",
    "while not (project_root / \"src\").is_dir():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "print(\"Erkannte Projektwurzel:\", project_root)\n",
    "\n",
    "# Projektwurzel in den PYTHONPATH aufnehmen, damit `import src....` funktioniert.\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment-ID und Label-Parameter definieren\n",
    "\n",
    "In dieser Zelle lege ich fest:\n",
    "\n",
    "- `EXP_ID`: eine eindeutige Bezeichnung f\\u00fcr dieses Experiment.\n",
    "- `LABEL_PARAMS`: alle Parameter, die die Label-Logik bestimmen (Horizont, Schwellen, Monotonie).\n",
    "- `OVERSAMPLE_FACTOR`: sp\\u00e4ter relevant f\\u00fcr das Oversampling der `signal=1`-F\\u00e4lle im Training.\n",
    "\n",
    "Die Idee ist, dass jede Kombination dieser Parameter als eigene Version gespeichert wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment-Konfiguration\n",
    "EXP_ID = \"v1_h4_thr0p5pct_strict\"  # frei w\\u00e4hlbarer Name f\\u00fcr dieses Experiment\n",
    "\n",
    "LABEL_PARAMS = dict(\n",
    "    horizon_days=4,\n",
    "    up_threshold=0.005,    # +0.5 % Lookahead-Return \\u00fcber 4 Tage\n",
    "    down_threshold=-0.005, # -0.5 % Lookahead-Return \\u00fcber 4 Tage\n",
    "    strict_monotonic=True, # Pfad t..t+4 muss streng steigend/fallend sein\n",
    ")\n",
    "\n",
    "# Wird sp\\u00e4ter im Trainings-Notebook verwendet, um die Bewegungs-Tage zu oversamplen.\n",
    "OVERSAMPLE_FACTOR = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Labels und Trainingsdatensatz automatisch erzeugen\n",
    "\n",
    "Die folgende Zelle erledigt den kompletten Daten-Vorbereitungsschritt automatisch:\n",
    "\n",
    "1. `label_eurusd(**LABEL_PARAMS)` berechnet die Labels im Speicher.\n",
    "2. Es werden zwei Label-Dateien geschrieben:\n",
    "   - `data/processed/fx/eurusd_labels__<EXP_ID>.csv` (archivierte Version f\\u00fcr dieses Experiment)\n",
    "   - `data/processed/fx/eurusd_labels.csv` (aktuelle Standardversion)\n",
    "3. `build_training_dataframe(exp_id=EXP_ID)` erzeugt den passenden Trainingsdatensatz aus Labels + News.\n",
    "4. Es werden zwei Trainingsdateien geschrieben:\n",
    "   - `data/processed/datasets/eurusd_news_training__<EXP_ID>.csv` (archivierte Version)\n",
    "   - `data/processed/datasets/eurusd_news_training.csv` (aktuelle Standardversion)\n",
    "\n",
    "So muss ich im Terminal **nichts mehr manuell ausf\\u00fchren**; alle relevanten CSVs entstehen beim\n",
    "Start des Experiments direkt im Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.label_eurusd import label_eurusd\n",
    "from src.data.build_training_set import build_training_dataframe\n",
    "from src.utils.io import DATA_PROCESSED\n",
    "\n",
    "# 1) Labels im Speicher berechnen (EURUSD-Zeitreihe + Lookahead-Logik).\n",
    "labels = label_eurusd(**LABEL_PARAMS)\n",
    "\n",
    "# Verzeichnis f\\u00fcr Label-Dateien sicherstellen.\n",
    "fx_dir = DATA_PROCESSED / \"fx\"\n",
    "fx_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Archiv-Datei mit Experiment-ID, z. B.: eurusd_labels__v1_h4_thr0p5pct_strict.csv\n",
    "labels_path_exp = fx_dir / f\"eurusd_labels__{EXP_ID}.csv\"\n",
    "labels.to_csv(labels_path_exp)\n",
    "\n",
    "# \"Aktuelle\" Datei ohne Suffix (f\\u00fcr Default-Nutzung in anderen Skripten).\n",
    "labels_path_latest = fx_dir / \"eurusd_labels.csv\"\n",
    "labels.to_csv(labels_path_latest)\n",
    "\n",
    "print(\"[ok] Labels gespeichert als:\")\n",
    "print(\"  \", labels_path_exp)\n",
    "print(\"  \", labels_path_latest)\n",
    "\n",
    "# 2) Trainingsdatensatz aus Labels + News bauen.\n",
    "# build_training_dataframe verwendet durch exp_id automatisch die passende Label-Datei.\n",
    "merged = build_training_dataframe(exp_id=EXP_ID)\n",
    "\n",
    "ds_dir = DATA_PROCESSED / \"datasets\"\n",
    "ds_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Archiv-Trainingsdatensatz mit Experiment-ID, z. B.: eurusd_news_training__v1_h4_thr0p5pct_strict.csv\n",
    "train_path_exp = ds_dir / f\"eurusd_news_training__{EXP_ID}.csv\"\n",
    "merged.to_csv(train_path_exp, index=False)\n",
    "\n",
    "# \"Aktueller\" Trainingsdatensatz ohne Suffix.\n",
    "train_path_latest = ds_dir / \"eurusd_news_training.csv\"\n",
    "merged.to_csv(train_path_latest, index=False)\n",
    "\n",
    "print(\"[ok] Trainingsdatensatz gespeichert als:\")\n",
    "print(\"  \", train_path_exp)\n",
    "print(\"  \", train_path_latest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trainingsdatensatz f\\u00fcr dieses Experiment laden\n",
    "\n",
    "Ab hier kann ich im gleichen Notebook oder in weiteren Modell-Notebooks mit dem Datensatz\n",
    "\n",
    "```text\n",
    "data/processed/datasets/eurusd_news_training__<EXP_ID>.csv\n",
    "```\n",
    "\n",
    "weiterarbeiten. Die folgende Zelle zeigt, wie der Datensatz eingelesen wird;\n",
    "der Rest (Train/Val/Test-Split, XGBoost-Training, Auswertung) kann dann wie bisher erfolgen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = DATA_PROCESSED / \"datasets\" / f\"eurusd_news_training__{EXP_ID}.csv\"\n",
    "print(\"Verwende Datensatz:\", dataset_path)\n",
    "\n",
    "df = pd.read_csv(dataset_path, parse_dates=[\"date\"])\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
